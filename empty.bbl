\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{tfidf}
Aizawa, A.: An information-theoretic perspective of tf--idf measures.
  Information Processing \& Management  39(1),  45--65 (2003)

\bibitem{becker}
Becker, L., Basu, S., Vanderwende, L.: Mind the gap: learning to choose gaps
  for question generation. In: Proceedings of the 2012 Conference of the North
  American Chapter of the Association for Computational Linguistics: Human
  Language Technologies. pp. 742--751. Association for Computational
  Linguistics (2012)

\bibitem{neural}
Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N.,
  Hullender, G.: Learning to rank using gradient descent. In: Proceedings of
  the 22nd international conference on Machine learning. pp. 89--96. ACM (2005)

\bibitem{colby1971artificial}
Colby, K.M., Weber, S., Hilf, F.D.: Artificial paranoia. Artificial
  Intelligence  2(1),  1--25 (1971)

\bibitem{DBLP:journals/corr/DuSC17}
Du, X., Shao, J., Cardie, C.: Learning to ask: Neural question generation for
  reading comprehension. CoRR  abs/1705.00106 (2017),
  \url{http://arxiv.org/abs/1705.00106}

\bibitem{duke2008effective}
Duke, N.K., Pearson, P.D.: Effective practices for developing reading
  comprehension. The Journal of Education  189(1/2),  107--122 (2008)

\bibitem{NIPS2016_6469}
He, D., Xia, Y., Qin, T., Wang, L., Yu, N., Liu, T., Ma, W.Y.: Dual learning
  for machine translation. In: Lee, D.D., Sugiyama, M., Luxburg, U.V., Guyon,
  I., Garnett, R. (eds.) Advances in Neural Information Processing Systems 29,
  pp. 820--828. Curran Associates, Inc. (2016),
  \url{http://papers.nips.cc/paper/6469-dual-learning-for-machine-translation.pdf}

\bibitem{heilman2010good}
Heilman, M., Smith, N.A.: Good question! statistical ranking for question
  generation. In: Human Language Technologies: The 2010 Annual Conference of
  the North American Chapter of the Association for Computational Linguistics.
  pp. 609--617. Association for Computational Linguistics (2010)

\bibitem{Kunichika2001AutomatedQG}
Kunichika, H., Katayama, T., Hirashima, T., Takeuchi, A.: Automated question
  generation methods for intelligent english learning systems and its
  evaluation (2001)

\bibitem{lindberg2013generating}
Lindberg, D., Popowich, F., Nesbit, J., Winne, P.: Generating natural language
  questions to support learning on-line  (2013)

\bibitem{stanford}
Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J.R., Bethard, S., McClosky,
  D.: The stanford corenlp natural language processing toolkit. In: ACL (System
  Demonstrations). pp. 55--60 (2014)

\bibitem{mazidi2014linguistic}
Mazidi, K., Nielsen, R.D.: Linguistic considerations in automatic question
  generation. In: ACL (2). pp. 321--326 (2014)

\bibitem{infusing}
Mazidi, K., Tarau, P.: Infusing nlu into automatic question generation. In:
  INLG. pp. 51--60 (2016)

\bibitem{mihalcea2004graph}
Mihalcea, R.: Graph-based ranking algorithms for sentence extraction, applied
  to text summarization. In: Proceedings of the ACL 2004 on Interactive poster
  and demonstration sessions. p.~20. Association for Computational Linguistics
  (2004)

\bibitem{textrank}
Mihalcea, R., Tarau, P.: Textrank: Bringing order into text. In: EMNLP. vol.~4,
  pp. 404--411 (2004)

\bibitem{mostafazadeh2016generating}
Mostafazadeh, N., Misra, I., Devlin, J., Mitchell, M., He, X., Vanderwende, L.:
  Generating natural questions about an image. arXiv preprint arXiv:1603.06059
  (2016)

\bibitem{mostow2009generating}
Mostow, J., Chen, W.: Generating instruction automatically for the reading
  strategy of self-questioning. In: AIED. pp. 465--472 (2009)

\bibitem{Popel}
Popel, M., Mareƒçek, D.: Perplexity of n-gram and dependency language models

\bibitem{rajpurkar2016squad}
Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: Squad: 100,000+ questions for
  machine comprehension of text. arXiv preprint arXiv:1606.05250  (2016)

\bibitem{rus2010first}
Rus, V., Wyse, B., Piwek, P., Lintean, M., Stoyanchev, S., Moldovan, C.: The
  first question generation shared task evaluation challenge. In: Proceedings
  of the 6th International Natural Language Generation Conference. pp.
  251--257. Association for Computational Linguistics (2010)

\bibitem{serban2016generating}
Serban, I.V., Garc{\'\i}a-Dur{\'a}n, A., Gulcehre, C., Ahn, S., Chandar, S.,
  Courville, A., Bengio, Y.: Generating factoid questions with recurrent neural
  networks: The 30m factoid question-answer corpus. arXiv preprint
  arXiv:1603.06807  (2016)

\bibitem{Susanti2017}
Susanti, Y., Tokunaga, T., Nishikawa, H., Obari, H.: Evaluation of
  automatically generated english vocabulary questions. Research and Practice
  in Technology Enhanced Learning  12(1), ~11 (Mar 2017),
  \url{https://doi.org/10.1186/s41039-017-0051-y}

\bibitem{DBLP:journals/corr/VinyalsTBE14}
Vinyals, O., Toshev, A., Bengio, S., Erhan, D.: Show and tell: {A} neural image
  caption generator. CoRR  abs/1411.4555 (2014),
  \url{http://arxiv.org/abs/1411.4555}

\bibitem{wolfe}
Wolfe, J.H.: Automatic question generation from text-an aid to independent
  study. ACM SIGCSE Bulletin  8(1),  104--112 (1976)

\bibitem{yao}
Yao, X., Tosch, E., Chen, G., Nouri, E., Artstein, R., Leuski, A., Sagae, K.,
  Traum, D.: Creating conversational characters using question generation
  tools. Dialogue \& Discourse  3(2),  125--146 (2012)

\bibitem{zhu2016deep}
Zhu, H., Zhang, P., Sun, C.: Deep q-learning with prioritized sampling. In:
  Neural Information Processing: 23rd International Conference, ICONIP 2016,
  Kyoto, Japan, October 16--21, 2016, Proceedings. vol. 9947, p.~13. Springer
  (2016)

\end{thebibliography}
